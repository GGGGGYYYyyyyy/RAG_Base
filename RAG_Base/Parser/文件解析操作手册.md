# EnhancedMarkdownParser 操作手册

---

## 一、功能概述
本解析器支持以下核心功能：
1. Markdown解析与智能分块
2. 表格中文描述化转换（支持Markdown/HTML表格）
3. 数据库元数据关联（MySQL支持）
4. 自定义分块策略与标题层级提取

---

## 二、环境依赖
```bash
pip install pymysql
```

---

## 三、初始化参数配置
```python
parser = EnhancedMarkdownParser(
    max_chunk_size=1000,          # 最大块大小（字符数）
    chunk_overlap=200,            # 分块重叠量
    contain_closest_title_levels=2, # 保留最近的标题层级数
    convert_table_to_text=True,   # 是否将表格转为中文描述
    separators=["\n\n", "\n", " ", ""], # 分块分隔符优先级列表
    remove_hyperlinks=False,      # 是否移除超链接
    remove_images=False,          # 是否移除图片
    encoding="utf-8",             # 文件编码
    allow_cross_header_content=False, # 是否允许跨标题分块
    db_config={                   # 数据库连接配置（可选）
        "host": "localhost",
        "user": "root",
        "password": "pass",
        "database": "rag_db"
    },
    target_db_extension=".pdf"    # 数据库匹配文件扩展名
)
```

---

## 四、使用流程

### 1. 基础解析流程
```python
# 解析文件并获取分块结果
chunks = parser.parse_file(
    file_path="example.md",              # 待解析文件路径
    doc_title="文档标题",                # 自定义文档标题（可选）
    db_resource_name_for_metadata="example.pdf"  # 数据库匹配键（可选）
)

# 保存结果到JSON
parser.save_to_json("output.json")
```

### 2. 直接解析文本
```python
chunks = parser.parse(
    markdown="# 内容标题\n正文内容...",
    doc_title="内存解析示例"
)
```

---

## 五、关键功能说明

### 1. 表格处理模式
| 模式 | 参数设置 | 输出形式 |
|------|---------|----------|
| 中文描述 | `convert_table_to_text=True` | 自然语言描述表格内容 |
| 原始表格 | `convert_table_to_text=False` | 保留原始表格结构 |

### 2. 分块策略
- **分隔符优先级**：按`separators`列表顺序尝试切分
- **标题继承**：自动关联最近`contain_closest_title_levels`级标题
- **重叠处理**：通过`chunk_overlap`参数控制上下文重叠

### 3. 数据库集成
1. 需提前创建表 `Rag_dataBase`，字段要求：
   ```sql
   CREATE TABLE Rag_dataBase (
       resourceId VARCHAR(255),
       dcId VARCHAR(255),
       resourceName VARCHAR(255) PRIMARY KEY,  -- 匹配文件名字段
       originFileName VARCHAR(255)
   )
   ```
2. 查询逻辑：
   - 默认使用`{filename}.pdf`作为查询键
   - 可通过`db_resource_name_for_metadata`参数自定义查询键

---

## 六、输出格式说明
每个分块包含以下字段：
```json
{
  "content": "# 文档标题 --- 章节标题\n分块内容...",
  "metadata": {
    "chunk_id": "唯一ID",
    "doc_title": "文档标题",
    "section_title": "所属章节",
    "type": "内容类型(text/table)",
    "resourceId": "...",  // 数据库关联字段
    "dcId": "..."
  }
}
```

---

## 七、典型应用场景

### 场景1：长文档精细切分
```python
# 配置小颗粒分块
parser = EnhancedMarkdownParser(
    max_chunk_size=500,
    chunk_overlap=100,
    separators=["\n## ", "\n### ", "\n\n", "\n", "。"]
)
```

### 场景2：纯文本提取模式
```python
# 移除所有非文本元素
parser = EnhancedMarkdownParser(
    remove_hyperlinks=True,
    remove_images=True,
    convert_table_to_text=True
)
```

---

## 八、常见问题处理

### 1. 分块过大的解决方法
- 调小`max_chunk_size`
- 增加更细粒度的分隔符（如句号`。`）
- 启用标题跨块限制`allow_cross_header_content=False`

### 2. 数据库查询失败
- 检查`resourceName`字段是否匹配
- 验证数据库连接配置
- 确认表结构是否包含必要字段

### 3. 特殊字符乱码
- 确保文件编码与`encoding`参数一致
- 尝试设置`encoding="utf-8-sig"`处理BOM头

---

## 九、完整示例
```python
# 初始化解析器
parser = EnhancedMarkdownParser(
    max_chunk_size=800,
    chunk_overlap=150,
    convert_table_to_text=True,
    db_config={
        "host": "localhost",
        "user": "root",
        "password": "123456",
        "database": "rag_db"
    }
)

# 解析文件
chunks = parser.parse_file(
    file_path="test.md",
    doc_title="测试文档",
    db_resource_name_for_metadata="test.pdf"
)

# 保存结果
parser.save_to_json("result.json", ensure_ascii=False, indent=2)
```

---

## 十、维护注意事项
1. 定期检查数据库连接状态
2. 大文件处理时建议配合日志监控
3. 修改分隔符时需遵循优先级顺序（从最严格到最宽松）
4. 表格处理性能优化：禁用`convert_table_to_text`可提升速度

> 提示：使用`close_db_connection()`方法在处理完成后关闭数据库连接